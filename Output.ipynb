{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Output.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJwO7WhiCSRK"
      },
      "source": [
        "!git clone https://github.com/visirion07/mpiigaze.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReLDB6jwt2X0"
      },
      "source": [
        "import os\n",
        "\n",
        "import csv\n",
        "import sys\n",
        "from spacy.lang.en import English\n",
        "from io import open\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import nltk\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from nltk.tokenize import word_tokenize\n",
        "import operator\n",
        "from queue import PriorityQueue\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
        "# from nltk.translate.meteor_score import single_meteor_score\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTgxdja1t-kn",
        "outputId": "02bbe85d-dbd0-4c0c-9db6-a6b1e2cc0b54"
      },
      "source": [
        "datag = {}\n",
        "tot = 0\n",
        "for f in os.listdir(\"/content/mpiigaze/outputs\"):\n",
        "  person = int(f.split('.')[0][1:-1])\n",
        "  if (f.split('.')[0][-1]!='b'):\n",
        "    # print(f)\n",
        "    continue\n",
        "  print(f)\n",
        "  arr = np.load(\"/content/mpiigaze/outputs/\" + f, allow_pickle = True)\n",
        "  datag[person] = {}\n",
        "  tot += arr.shape[0]\n",
        "  datag[person][\"gaze\"] = []\n",
        "  datag[person][\"gazep\"] = []\n",
        "  datag[person][\"z_app\"] = []\n",
        "  datag[person][\"z_gaze\"] = []\n",
        "  datag[person][\"head\"] = []\n",
        "  datag[person][\"R\"] = []\n",
        "  for op in arr:\n",
        "    datag[person][\"gaze\"].append(op[0])\n",
        "    datag[person][\"gazep\"].append(op[3])\n",
        "    datag[person][\"z_gaze\"].append(op[2].reshape(-1, 6))\n",
        "    datag[person][\"z_app\"].append(op[1])\n",
        "    datag[person][\"head\"].append(op[-4])\n",
        "    datag[person][\"R\"].append(op[-2])\n",
        "  datag[person][\"gaze\"] =  np.array(datag[person][\"gaze\"])\n",
        "  datag[person][\"head\"] =  np.array(datag[person][\"head\"])  \n",
        "  datag[person][\"gazep\"] = np.squeeze(np.array(datag[person][\"gazep\"]), axis = 1)\n",
        "  datag[person][\"z_app\"] = np.squeeze(np.array(datag[person][\"z_app\"]), axis = 1)\n",
        "  datag[person][\"z_gaze\"] = np.squeeze(np.array(datag[person][\"z_gaze\"]), axis = 1)\n",
        "  datag[person][\"R\"] = np.array(datag[person][\"R\"])\n",
        "  print(person)\n",
        "  print(datag[person][\"gaze\"].shape)\n",
        "  print(datag[person][\"gazep\"].shape)\n",
        "  print(datag[person][\"z_app\"].shape)\n",
        "  print(datag[person][\"z_gaze\"].shape)\n",
        "  print(datag[person][\"head\"].shape)\n",
        "  print(datag[person][\"R\"].shape)\n",
        "print(\"Total data \", tot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p01b.npy\n",
            "1\n",
            "(24143, 2)\n",
            "(24143, 3)\n",
            "(24143, 64)\n",
            "(24143, 6)\n",
            "(24143, 2)\n",
            "(24143, 3, 3)\n",
            "p04b.npy\n",
            "4\n",
            "(16831, 2)\n",
            "(16831, 3)\n",
            "(16831, 64)\n",
            "(16831, 6)\n",
            "(16831, 2)\n",
            "(16831, 3, 3)\n",
            "p13b.npy\n",
            "13\n",
            "(1498, 2)\n",
            "(1498, 3)\n",
            "(1498, 64)\n",
            "(1498, 6)\n",
            "(1498, 2)\n",
            "(1498, 3, 3)\n",
            "p08b.npy\n",
            "8\n",
            "(10701, 2)\n",
            "(10701, 3)\n",
            "(10701, 64)\n",
            "(10701, 6)\n",
            "(10701, 2)\n",
            "(10701, 3, 3)\n",
            "p02b.npy\n",
            "2\n",
            "(28019, 2)\n",
            "(28019, 3)\n",
            "(28019, 64)\n",
            "(28019, 6)\n",
            "(28019, 2)\n",
            "(28019, 3, 3)\n",
            "p14b.npy\n",
            "14\n",
            "(1500, 2)\n",
            "(1500, 3)\n",
            "(1500, 64)\n",
            "(1500, 6)\n",
            "(1500, 2)\n",
            "(1500, 3, 3)\n",
            "p09b.npy\n",
            "9\n",
            "(7995, 2)\n",
            "(7995, 3)\n",
            "(7995, 64)\n",
            "(7995, 6)\n",
            "(7995, 2)\n",
            "(7995, 3, 3)\n",
            "p11b.npy\n",
            "11\n",
            "(2982, 2)\n",
            "(2982, 3)\n",
            "(2982, 64)\n",
            "(2982, 6)\n",
            "(2982, 2)\n",
            "(2982, 3, 3)\n",
            "p10b.npy\n",
            "10\n",
            "(2810, 2)\n",
            "(2810, 3)\n",
            "(2810, 64)\n",
            "(2810, 6)\n",
            "(2810, 2)\n",
            "(2810, 3, 3)\n",
            "p03b.npy\n",
            "3\n",
            "(35075, 2)\n",
            "(35075, 3)\n",
            "(35075, 64)\n",
            "(35075, 6)\n",
            "(35075, 2)\n",
            "(35075, 3, 3)\n",
            "p07b.npy\n",
            "7\n",
            "(15509, 2)\n",
            "(15509, 3)\n",
            "(15509, 64)\n",
            "(15509, 6)\n",
            "(15509, 2)\n",
            "(15509, 3, 3)\n",
            "p05b.npy\n",
            "5\n",
            "(16577, 2)\n",
            "(16577, 3)\n",
            "(16577, 64)\n",
            "(16577, 6)\n",
            "(16577, 2)\n",
            "(16577, 3, 3)\n",
            "p12b.npy\n",
            "12\n",
            "(1609, 2)\n",
            "(1609, 3)\n",
            "(1609, 64)\n",
            "(1609, 6)\n",
            "(1609, 2)\n",
            "(1609, 3, 3)\n",
            "p06b.npy\n",
            "6\n",
            "(18448, 2)\n",
            "(18448, 3)\n",
            "(18448, 64)\n",
            "(18448, 6)\n",
            "(18448, 2)\n",
            "(18448, 3, 3)\n",
            "p00b.npy\n",
            "0\n",
            "(29961, 2)\n",
            "(29961, 3)\n",
            "(29961, 64)\n",
            "(29961, 6)\n",
            "(29961, 2)\n",
            "(29961, 3, 3)\n",
            "Total data  213658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSQSymw08ZWq"
      },
      "source": [
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jmqLurKGC8a"
      },
      "source": [
        "def mean_angle_loss(pred, truth):\n",
        "    '''\n",
        "    :param pred,truth: type=torch.Tensor\n",
        "    :return:\n",
        "    '''\n",
        "    pred = pred.detach().numpy()\n",
        "    ans = 0\n",
        "    for i in range(len(pred)):\n",
        "        p_x, p_y, p_z = (pred[i][j] for j in range(3))\n",
        "        t_x, t_y, t_z = (truth[i][j] for j in range(3))\n",
        "        \n",
        "        # print(\"p_x={}, p_y={}, p_z={}\".format(p_x, p_y, p_z))\n",
        "        # print(\"t_x={}, t_y={}, t_z={}\".format(t_x, t_y, t_z))\n",
        "        angles = (p_x * t_x + p_y * t_y + p_z * t_z)/(math.sqrt(p_x**2+p_y**2+p_z**2) * math.sqrt(t_x**2+t_y**2+t_z**2))\n",
        "        ans += math.acos(angles) * 180 / np.pi\n",
        "    return ans / len(pred)\n",
        "def angular_diff(py1, py2):\n",
        "  # xzLen = cos(pitch)\n",
        "  # x = xzLen * cos(yaw)\n",
        "  # y = sin(pitch)\n",
        "  # z = xzLen * sin(-yaw)\n",
        "  xz1 = math.cos(py1[0])\n",
        "  x1 = xz1*math.cos(py1[1])\n",
        "  y1 = math.sin(py1[0])\n",
        "  z1 = xz1 * math.sin(-py1[1])\n",
        "  y_1 = [x1, y1, z1]\n",
        "\n",
        "  xz2 = math.cos(py2[0])\n",
        "  x2 = xz2*math.cos(py2[1])\n",
        "  y2 = math.sin(py2[0])\n",
        "  z2 = xz2 * math.sin(-py2[1])\n",
        "  y_2 = [x2, y2, z2]\n",
        "\n",
        "  angle_dot = (x1 * x2 + y1*y2 + z1 * z2)/(math.sqrt(x1**2+y1**2+z1**2) * math.sqrt(x2**2+ y2**2+z2**2))\n",
        "  ans = math.acos(angle_dot) * 180 / np.pi\n",
        "  return ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAT4Dz6JCmbj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg71B3hDxswE"
      },
      "source": [
        "class Gazeo(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(Gazeo, self).__init__()\n",
        "    self.fcc1 = nn.Linear(input_size, 64)\n",
        "    self.fcc2 = nn.Linear(64, 3)\n",
        "    self.drop = nn.Dropout(0.2)\n",
        "    self.act = nn.ReLU()\n",
        "  def forward(self, input, output):\n",
        "    expand = self.drop(self.fcc1(input))\n",
        "    expan = self.act(expand)\n",
        "    out = self.fcc2(expan)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xnMIpAWjG-w"
      },
      "source": [
        "class Gazeonly(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(Gazeonly, self).__init__()\n",
        "    self.fcc1 = nn.Linear(input_size, 64)\n",
        "    self.fcc2 = nn.Linear(64, 3)\n",
        "    self.act = nn.ReLU()\n",
        "  def forward(self, input, output):\n",
        "    expand = self.fcc1(input)\n",
        "    expan = self.act(expand)\n",
        "    out = self.fcc2(expan)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmWfyyfvB5jG"
      },
      "source": [
        "class Gaze(nn.Module):\n",
        "  def __init__(self, input_1_size, input_2_size):\n",
        "    super(Gaze, self).__init__()\n",
        "    self.fcc1 = nn.Linear(input_1_size, 24)\n",
        "    self.fcc2 = nn.Linear(input_2_size, 16)\n",
        "    self.fcc3 = nn.Linear(input_2_size, 8)\n",
        "    self.fcc4 = nn.Linear(40, 16)\n",
        "    self.fcc5 = nn.Linear(16, 8)\n",
        "    self.fcc6 = nn.Linear(16, 8)\n",
        "    self.fcc7 = nn.Linear(8, 3)\n",
        "    self.act = nn.ReLU()\n",
        "  def forward(self, input1, input2, output):\n",
        "    # print(input1.shape)\n",
        "    minimize_1 = self.fcc1(input1)\n",
        "    min_1 = self.act(minimize_1)\n",
        "    # print(min_1.shape)\n",
        "    minimize_2 = self.fcc2(input2)\n",
        "    min_2 = self.act(minimize_2)\n",
        "    # print(min_2.shape)\n",
        "    min_3 = self.fcc3(input2)\n",
        "    concat_1 = torch.cat((min_1, min_2), 1)\n",
        "    # print(concat_1.shape)\n",
        "    minimize_4 = self.fcc4(concat_1)\n",
        "    min_4 = self.act(minimize_4)\n",
        "    min_6 = self.fcc6(min_4)\n",
        "    # min_6 = self.fcc6(min_5)\n",
        "    output_h = self.fcc7(min_6)\n",
        "    # print(min_4.shape, min_6.shape, output_h.shape)\n",
        "    return output_h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LTHDPmTjvbJ"
      },
      "source": [
        "class BigGaze(nn.Module):\n",
        "  def __init__(self, input_1_size, input_2_size):\n",
        "    super(BigGaze, self).__init__()\n",
        "    self.fcc1 = nn.Linear(64, 32)\n",
        "    self.fcc2 = nn.Linear(32, 16)\n",
        "    self.fcc3 = nn.Linear(16, 6)\n",
        "    self.fcc4 = nn.Linear(6, 12)\n",
        "    self.fcc5 = nn.Linear(18, 3)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.act3 = nn.ReLU()\n",
        "    self.act4 = nn.ReLU()\n",
        "\n",
        "  def forward(self, input1, input2, output):\n",
        "    # print(input1.shape, input2.shape)\n",
        "    exp = self.act1(self.fcc1(input1))\n",
        "    exp_1 =  self.act2(self.fcc2(exp))\n",
        "    mini =  self.act3(self.fcc3(exp_1))\n",
        "    mini_1 =  self.act4(self.fcc4(input2))\n",
        "    comb = torch.cat((mini, mini_1), 1)\n",
        "    comb1 =  self.fcc5(comb)\n",
        "\n",
        "    # output_h = self.fcc11(self.fcc10(comb1))\n",
        "    \n",
        "    return comb1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvIRWPOdCyKn"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def nn_angular_distance(a, b):\n",
        "    sim = F.cosine_similarity(a, b, eps=1e-6)\n",
        "    sim = F.hardtanh(sim, -1.0 + 1e-6, 1.0 - 1e-6)\n",
        "    return torch.acos(sim) * (180 / np.pi)\n",
        "\n",
        "\n",
        "class GazeAngularLoss(object):\n",
        "\n",
        "    def __init__(self, key_true='gaze_a', key_pred='gaze_a_hat'):\n",
        "        self.key_true = key_true\n",
        "        self.key_pred = key_pred\n",
        "\n",
        "    def __call__(self, gaze_a, gaze_hat):\n",
        "        def pitchyaw_to_vector(pitchyaws):\n",
        "            sin = torch.sin(pitchyaws)\n",
        "            cos = torch.cos(pitchyaws)\n",
        "            return torch.stack([cos[:, 0] * sin[:, 1], sin[:, 0], cos[:, 0] * cos[:, 1]], 1)\n",
        "        y = pitchyaw_to_vector(gaze_a).detach()\n",
        "        y_hat = gaze_hat\n",
        "        if y_hat.shape[1] == 2:\n",
        "            y_hat = pitchyaw_to_vector(y_hat)\n",
        "        return torch.mean(nn_angular_distance(y, y_hat))\n",
        "def mean_angle_loss(pred, truth):\n",
        "    '''\n",
        "    :param pred,truth: type=torch.Tensor\n",
        "    :return:\n",
        "    '''\n",
        "    pred = pred.detach().numpy()\n",
        "    ans = 0\n",
        "    for i in range(len(pred)):\n",
        "        p_x, p_y, p_z = (pred[i][j] for j in range(3))\n",
        "        t_x, t_y, t_z = (truth[i][j] for j in range(3))\n",
        "        # print(\"p_x={}, p_y={}, p_z={}\".format(p_x, p_y, p_z))\n",
        "        # print(\"t_x={}, t_y={}, t_z={}\".format(t_x, t_y, t_z))\n",
        "        angles = (p_x * t_x + p_y * t_y + p_z * t_z)/(math.sqrt(p_x**2+p_y**2+p_z**2) * math.sqrt(t_x**2+t_y**2+t_z**2))\n",
        "        ans += math.acos(angles) * 180 / np.pi\n",
        "    return ans / len(pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzvLsbuPC6pB"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "# use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "import time\n",
        "def mtrain(train_iter, model, opt, loss_fn):\n",
        "  model.train()\n",
        "  total_loss=0\n",
        "  overall_loss=0\n",
        "  st = time.time()\n",
        "  for b, batch in enumerate(train_iter):\n",
        "    inp1 = batch[0].to(device)\n",
        "    # inp2 = batch[1].to(device)\n",
        "    out = batch[2].to(device)\n",
        "    # print(inp1.shape, inp2.shape, out.shape)\n",
        "    optimizer.zero_grad()\n",
        "    # output = model(inp2,inp1,out)\n",
        "    output = model(inp1, out)  \n",
        "    # print(\"hey\")\n",
        "    # print(output.shape)\n",
        "    loss = loss_fn(out, output)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.data.item()\n",
        "    overall_loss += loss.data.item()\n",
        "    if b % 100 == 0 and b != 0:\n",
        "      total_loss = total_loss / 100\n",
        "  return overall_loss/len(train_iter)\n",
        "def evaluate(val_iter, model, loss_fn):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    for b, batch in enumerate(val_iter):\n",
        "      inp1 = batch[0].to(device)\n",
        "      # inp2 = batch[1].to(device)\n",
        "      out = batch[2].to(device)\n",
        "      # output = model(inp2, inp1, out)\n",
        "      output = model(inp1, out)\n",
        "\n",
        "      loss = loss_fn(out, output)\n",
        "      total_loss += loss.data.item()\n",
        "    return total_loss/len(val_iter)\n",
        "\n",
        "def eval(iter, loss_fn):\n",
        "  with torch.no_grad():\n",
        "    # model.eval()\n",
        "    total_loss = 0\n",
        "    for b, batch in enumerate(iter):\n",
        "      out = batch[2].to(device)\n",
        "      out1 = batch[3].to(device)\n",
        "      loss = loss_fn(out, out1)\n",
        "      total_loss += loss.data.item()\n",
        "    return total_loss/len(iter)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiAUN2jxC7eL"
      },
      "source": [
        "for seed in [0, 2, 12, 22, 32, 42]:\n",
        "  print(\"---------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  print(\"computing for seed\", seed)\n",
        "  best_v =[]\n",
        "  best_ts = []\n",
        "  face_gazes = []\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  dic_p = [0 for _ in range(15)]\n",
        "  #begin cross person training-evaluation loop\n",
        "  for leave_out in range(15):\n",
        "    start_time_person = time.time()\n",
        "    data = []\n",
        "    train = []\n",
        "    test = []\n",
        "    val = []\n",
        "    cnt_test = datag[leave_out][\"gaze\"].shape[0]\n",
        "    for i in range(cnt_test):\n",
        "      test.append([datag[leave_out][\"z_gaze\"][i], datag[leave_out][\"z_app\"][i], datag[leave_out][\"gaze\"][i], datag[leave_out][\"gazep\"][i]])\n",
        "    \n",
        "    pq = 0\n",
        "    for key in datag.keys():\n",
        "      if(key==leave_out):\n",
        "        continue\n",
        "      else:\n",
        "        cnt = datag[key][\"gaze\"].shape[0]\n",
        "        pq += cnt\n",
        "        for i in range(cnt):\n",
        "          data.append([datag[key][\"z_gaze\"][i], datag[key][\"z_app\"][i], datag[key][\"gaze\"][i], datag[key][\"gazep\"][i]])\n",
        "    np.random.shuffle(test)\n",
        "    np.random.shuffle(data)\n",
        "    print(\"Data Length\", len(data))\n",
        "    print(\"Test Length\", len(test))\n",
        "\n",
        "    frc = 0.1\n",
        "    llo =  int(frc * len(data))\n",
        "    train = data[:-llo]\n",
        "    val = data[llo:]\n",
        "\n",
        "\n",
        "    x1_train = []\n",
        "    x1_val = []\n",
        "    x1_test = []\n",
        "\n",
        "    x2_train = []\n",
        "    x2_val = []\n",
        "    x2_test = []\n",
        "\n",
        "    y_train = []\n",
        "    y_val = []\n",
        "    y_test = []\n",
        "\n",
        "    yp_train = []\n",
        "    yp_val = []\n",
        "    yp_test = []\n",
        "\n",
        "\n",
        "\n",
        "    for ls in train:\n",
        "      x1_train.append(ls[0])\n",
        "      x2_train.append(ls[1])\n",
        "      y_train.append(ls[2])\n",
        "      yp_train.append(ls[3])\n",
        "\n",
        "    for ls in val:\n",
        "      x1_val.append(ls[0])\n",
        "      x2_val.append(ls[1])\n",
        "      y_val.append(ls[2])\n",
        "      yp_val.append(ls[3])\n",
        "\n",
        "    for ls in test:\n",
        "      x1_test.append(ls[0])\n",
        "      x2_test.append(ls[1])\n",
        "      y_test.append(ls[2])\n",
        "      yp_test.append(ls[3])\n",
        "\n",
        "    x1_train = torch.tensor(np.array(x1_train))\n",
        "    x1_val = torch.tensor(np.array(x1_val))\n",
        "    x1_test = torch.tensor(np.array(x1_test))\n",
        "\n",
        "    x2_train = torch.tensor(np.array(x2_train))\n",
        "    x2_val = torch.tensor(np.array(x2_val))\n",
        "    x2_test = torch.tensor(np.array(x2_test))\n",
        "\n",
        "    y_train = torch.tensor(np.array(y_train))\n",
        "    y_val = torch.tensor(np.array(y_val))\n",
        "    y_test = torch.tensor(np.array(y_test))\n",
        "\n",
        "    yp_train = torch.tensor(np.array(yp_train))\n",
        "    yp_val = torch.tensor(np.array(yp_val))\n",
        "    yp_test = torch.tensor(np.array(yp_test))\n",
        "\n",
        "\n",
        "    train = torch.utils.data.TensorDataset(x1_train,x2_train,y_train, yp_train)\n",
        "    train_data = torch.utils.data.DataLoader(train, batch_size=32)\n",
        "\n",
        "    dev = torch.utils.data.TensorDataset(x1_val,x2_val,y_val, yp_val)\n",
        "    dev_data = torch.utils.data.DataLoader(dev, batch_size=32)\n",
        "\n",
        "    test_ = torch.utils.data.TensorDataset(x1_test,x2_test,y_test, yp_test)\n",
        "    test_data = torch.utils.data.DataLoader(test_, batch_size=32)\n",
        "\n",
        "\n",
        "    \n",
        "    gaze2d = Gazeonly(6).to(device)\n",
        "    lr = 1e-1\n",
        "    n_epochs = 100\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    # loss_fn = torch.nn.SmoothL1Loss(reduction=\"mean\")\n",
        "    loss_fn2 = mean_angle_loss\n",
        "    loss_fn = GazeAngularLoss()\n",
        "    optimizer = optim.SGD(gaze2d.parameters(), lr=lr)\n",
        "    best_val = 100\n",
        "    best_epoch = -1\n",
        "    best_test = 100\n",
        "    patience = 2\n",
        "    cnt_patience_break  = 0\n",
        "    test_iter = iter(test_data)\n",
        "    facegaze = eval(test_iter, loss_fn)\n",
        "    sp = time.time()\n",
        "    for epoch in range(n_epochs):\n",
        "      print(\"epoch \", epoch)\n",
        "      train_iter = iter(train_data)\n",
        "      train_loss = mtrain(train_iter, gaze2d, optimizer, loss_fn)\n",
        "      train_losses.append(train_loss)\n",
        "      val_iter = iter(dev_data)\n",
        "      val_loss = evaluate(val_iter, gaze2d, loss_fn)\n",
        "      test_iter = iter(test_data)\n",
        "      test_loss = evaluate(test_iter, gaze2d, loss_fn)\n",
        "      val_losses.append(val_loss)\n",
        "      # print(epoch, train_loss, val_loss, test_loss)\n",
        "      print(\"Time for this epoch \", time.time()-sp, train_loss, val_loss) \n",
        "      sp = time.time()\n",
        "      if(val_loss < best_val):\n",
        "        best_val = val_loss\n",
        "        best_epoch = epoch\n",
        "        best_test = test_loss\n",
        "      else:\n",
        "        cnt_patience_break += 1\n",
        "        if(cnt_patience_break>=patience):\n",
        "          break\n",
        "    print(leave_out, best_val, best_test, facegaze, cnt_test)\n",
        "    dic_p[leave_out] += best_val\n",
        "    best_v.append(best_val)\n",
        "    best_ts.append(best_test) \n",
        "    face_gazes.append(facegaze)\n",
        "    print(time.time()-start_time_person)\n",
        "print(dic_p/6)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}